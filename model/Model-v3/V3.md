# MicrobeNet Version 3 documentation

## Convolution testing

Testing out the scharr convolution showed a 3% increase in accuracy.
This convolution kernel will be used for all future models.
The greyscaling also reduces computaitional complexity by 2/3


## Issues with Previous Versions

Version 2 suffered from three major drawbacks

1. Due to the use of arbitrary rules to seprate classes the model struggled to accurately classify. Some genera were 90+% accurate while others were 9%

2. Many of the genera in the dataset were actually species of other documented genera. Furthermore many genera only contained around 6-13 images thereby skewing the models predictions.

3. Due to the use of multiple models in conjunction the two models would have to be correct simultaneously for the results to be accurate. (90% * 88% => 79.2%) 


## Proposed Solutions

**Proposal 1**: Test both a single model and tree of models 
This is the most important change beacuse of the effect it will have on efficiency.
It is worth testing the efficacy of a single model to assess the data, thereby sidestepping the issue of classifying the images further.
For this model all genera with less than 200 images will be ignored thereby increasing accuracy

A tree type multi-model will also be tested.
This tree will be structured generally according to families of organisms, with any outliers being ignored.
This will allow for genera with less images to be kept.
Both a Eukaryote and Bacteria model will be trained.


**Proposal 2**: Use scharr Convolution
All models will use a scharr convolution to help speed along training.
The kernel for scharr is as follows:
```
[
 [-3 + 10i   0 + 10i   +3 + 10i]
 [-10 + 10i  0 + 10i  +10 + 10i]
 [-3 + 10i   0 + 10i   +3 + 10i]
]
```

**Proposal 3**: More data
Experimentations with smaller images will allow for more of the data to be used by the model.
The issue here is balancing image size and quantity for optimum performance.


## Experiment Results

**Unclassified Data**: One model was trained simply with the genera as categories
* Each images was processed to be 200 x 200 pixels, then copied with vertical and horizontal flip
* After the dataset was generated, a model very similar to the parent model from V2 was trained
* The end result of the training was an accuracy of: **78.5%**




**Classified Data**: One model was trained on data organized by taxonomy
* Each genus was put into class directories which were themselves divided into phylum directories
* Many models were trained on each level, one for phylum and many for each class.
* In the future this model should be used in conjuntion with information from the user.
* The final accuracy of the phylum classification model was: **92.85%**
* The final accuracy of the class classification model was: **75.5%**
* The final accuracy of the genus classification model was: **77.11%**


## Analysis
The above results show that there is a need for more images overall are required to train a better model
Another round of image scraping will be needed before continuing on to Version 4

Additionally I had some difficulty with the class and phylum models, due most likely to the scarcity and similarity of input data
Suprisingly the model seems to work better with an overarching knwoledge rather than specialization


